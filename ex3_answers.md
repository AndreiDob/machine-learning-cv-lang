# Exercise 3
### Question 17

For ease of explanation let's focus on a network with two input features and two nodes in each hidden layer. After passing and input example through the network, we get a prediction. From this prediction and a ground truth we can compute the prediction error. The function that computes this error is also called a cost function. Now, we know how bad we are doing overall. In order to improve our predictions, the only variables we can change are the weights inside the network. So, we want to somehow increase or decrease each weight in order to lower the cost function. Given the 2d example, we can imagine the graph of the cost function as a map with mountains, valleys, etc. We are at a certain point and want to get as low as possible, but we do not know in which way "down" is. The derivative of a function is the slope of the tangent to the graph of the function. So, if we were to compute the derivative of the cost function for a variable, that result, by telling us in which way the graph slopes, would tell us if if we should increase or decrease the value of that variable in order to lower the cost function. The slope gives us two pieces of information. The sign of the slope tells us in which direction we should go, while the value of the slope tells us how abrupt the graph is, thus giving us an idea of how much we should advance with our adjustment. So, in order to know how to adjust the weights, we start from the back, from the final cost function result. Then we compute the derivative of each of the weights that directly contributed to the computation of the final prediction. Theese weights will be the ones from the nodes in the last layer. Now we know how to adjust these weights for a better prediction based on measuring how much they influenced the final result error. So, the error was propagated from the final pint to the last set of weights. But theese weights were also computed based on the weights in the layer before them. Because now we know with cow much the last layer weights contribute to the final error, we can do the derivative trick again and find out how much the weights in the layer before the final one contribute to the final error. This goes on from the back of the network(where it starts) to the beginning and in the process, the contribution to the error of each weight is computed. Then with a simple adjustment, we get a better performing network. We repeat these steps until the cost does not decrease anymore and at that point we can say that we reached an optima. Wether if it is local or global and how to escape the local ones and set the learning rate is a discussion for another time.
