{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To make grading efficient and smooth we ask you to follow the rules:**\n",
    "\n",
    "<ol>\n",
    "<li>A single notebook file (without archiving) per group should be submitted via BB.  \n",
    "<li>Name of the notebook should be your group number, e.g., 01.ipynb or 21.ipynb, not <strike>group21.ipynb</strike> or <strike>group_1.ipynb</strike>.    \n",
    "<li>Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\".\n",
    "<li>Delete those cells that you inserted for your own debuging/testing purposes.\n",
    "</ol>\n",
    "\n",
    "**Not following these rules might result in point deduction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b>\n",
    "Be aware that some code or markdown cells are read-only to prevent you from changing them and complicating grading for graders.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overwrite this text** with a brief description who contributed to which parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete this cell** unless you would like to leave a message for graders or give a feedback about the assigment. Writing it here is better than in the BlackBoard submission textbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Processing with Recurrent Neural Networks\n",
    "\n",
    "So far, we have seen how word vectors can be constructed from corpus statistics, and how they can be utilized to infer latent semantic content either in isolation (e.g. genders from names) or in relation to one another (e.g. similarities and analogies). \n",
    "\n",
    "For tasks involving larger linguistic units such as phrases, sentences and dialogues, we need machinery capable of processing _sequences_ or _structures_ of words.\n",
    "\n",
    "Recurrent Neural Networks are an example of such machinery; for this assignment, you will construct a recurrent neural network that annotates each word of a sentence with a linguistically informative marker. In the simple case (and in this assignment), these markers will be POS tags. However, they can also be other kinds of tags, e.g. more fine-grained morphosyntactic [categories](https://en.wikipedia.org/wiki/Combinatory_categorial_grammar) (supertags).\n",
    "\n",
    "This task is a case of sequence labeling.  A good reference point is Jurafsky and Martin [Chapter 9](https://web.stanford.edu/~jurafsky/slp3/9.pdf). For a fuller view of the picture, a good reference point is Alex Graves' [dissertation](https://www.cs.toronto.edu/~graves/preprint.pdf).\n",
    "\n",
    "We will take a gradual approach, first inspecting recurrent neural networks, then moving on to data processing using high-grade word vectors before finally moving to the problem at hand. \n",
    "\n",
    "---\n",
    "\n",
    "There are 9 tasks in this assignment for a total of 15 points; tasks 1-2 and 6-9 are worth 2 points each, tasks 3-5 are worth 1 point each.\n",
    "\n",
    "Don't forget to add comments to your code and self-check frequently by printing data samples, data shapes, etc., but don't forget to delete unnecessary prints and cells before the submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks\n",
    "Recurrent Neural Networks are a particularly interesting class of neural networks. Unlike standard fully-connected networks that accept a fixed-size input and produce a fixed-size output over a predefined number of computational steps (i.e. network layers), RNNs instead operate on sequences of vectors. \n",
    "\n",
    "Computationally, feedforward networks may be seen as a trainable (but parametrically fixed) function, whereas RNNs act as continuous, stateful programs operating on sequences of inputs. \n",
    "Cognitively, this may be viewed as enhancing our system's perceptive and computational abilities with a notion of memory.\n",
    "In the general case, this statefulness is captured by an intermediate hidden vector which is adjusted throughout the computation, affected by both the immediately previous version of itself __and__ the current input.\n",
    "\n",
    "RNNs are nowadays established as the core machinery of neural sequence processing. \n",
    "\n",
    "A simple recurrent network (SRN or Elman network) is described by the equations:\n",
    "* $h_t = \\theta_h (W_h x_t + U_h h_{t-1} + b_h ) $\n",
    "* $y_t = \\theta_y (W_y h_t + b_y) $\n",
    "\n",
    "where (at timestep $t$) $x_t$, $h_t$, $y_t$ are the network's input, hidden and output representations respectively, $\\theta_h$, $\\theta_y$ are its hidden and output activation functions, and $W_h$, $U_h$, $b_h$, $W_y$, $b_y$ are the parametric tensors to be learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch ver=1.10.1+cu113\n",
      "numpy ver=1.23.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "print(f\"torch ver={torch.__version__}\\nnumpy ver={np.__version__}\")\n",
    "from torch import FloatTensor, LongTensor\n",
    "from typing import Tuple, List, Callable, Optional\n",
    "#to increase precision of printing floats \n",
    "#torch.set_printoptions(precision=8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following function to concisely convert torch tensors to numpy arrays before printing tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f918c917a2295612796d61ffd66e839c",
     "grade": false,
     "grade_id": "cell-5c81b94b5406d994",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tr2np(tensor):\n",
    "    \"\"\"Convert torch tensor into numpy array\"\"\"\n",
    "    return tensor.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (2 points): Our own SRN\n",
    "Let's make our own simple recurrent network from scratch, to get an idea of its inner workings. To make our life just a bit simpler, we will use `torch.nn.Linear` to model the internal transformations.\n",
    "\n",
    "Complete the `mySRN` class, which is initialized with the input $d_i$, hidden $d_h$ and output $d_o$ dimensionalities, as well as two non-linear functions $\\theta_h$ and $\\theta_y$, and constructs an SRN implementing three `torch.nn.Linear` layers:\n",
    "1. `x_to_h`: a layer that takes $x_t$ and produces $W_h x_t$\n",
    "2. `h_to_h`: a layer that takes $h_{t-1}$ and produces $U_h h_{t-1} + b_h$\n",
    "3. `h_to_y`: a layer that takes $h_t$ and produces $W_y h_t + b_y$\n",
    "\n",
    "Implement the function `step` that performs a computational step, accepting $x_t$ and $h_{t-1}$ and producing $h_t$ and $y_t$.\n",
    "\n",
    "Implement the function `forward` that accepts a List of inputs $X$, an initial hidden vector $h_{-1}$ and iteratively applies `step` until the input sequence is exhausted, returning a List of outputs $Y$ (of the same length as $X$).\n",
    "\n",
    "<font color=\"blue\">_Hint_: Note that `x_to_h` does not have a bias term $b$, since we will incorporate it into `h_to_h`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b9e59f3884ce17ff7bf3e59823640047",
     "grade": false,
     "grade_id": "task1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class mySRN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim: int, \n",
    "        hidden_dim: int, \n",
    "        output_dim: int, \n",
    "        hidden_activation: Callable[[FloatTensor], FloatTensor],\n",
    "        output_activation: Callable[[FloatTensor], FloatTensor],\n",
    "        device: str\n",
    "    ) -> None:\n",
    "        super(mySRN, self).__init__()\n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.output_activation = output_activation\n",
    "        self.device = device\n",
    "        #\n",
    "        self.x_to_h = torch.nn.Linear(in_features=input_dim, out_features=hidden_dim, bias=False)\n",
    "        self.h_to_h = torch.nn.Linear(in_features=hidden_dim, out_features=hidden_dim, bias=True)\n",
    "        self.h_to_y = torch.nn.Linear(in_features=hidden_dim, out_features=output_dim, bias=True)\n",
    "        \n",
    "    def step(self, x: FloatTensor, h: FloatTensor) -> Tuple[FloatTensor, FloatTensor]:\n",
    "        h_t= self.hidden_activation(self.x_to_h(x)+self.h_to_h(h))\n",
    "        y_t= self.output_activation(self.h_to_y(h_t))\n",
    "        return h_t,y_t\n",
    "    \n",
    "    def forward(self, X: List[FloatTensor], h: FloatTensor) -> List[FloatTensor]:\n",
    "        # detach elements of the Y lsit before returning\n",
    "        Y = []\n",
    "        for x in X:\n",
    "            h,y=self.step(x,h)\n",
    "            Y.append(y)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following toy RNN helps you to verify whether your implemention is correct.  \n",
    "Use the numbers below in the functions, and you can manually verify the output of the RNN.  \n",
    "This manual check will help you to see whether you are understanding calculations behind the RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "840e4c3458f339b37d1e278f84810d4b",
     "grade": true,
     "grade_id": "task1-assert",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X->H \n",
      "matrix:\n",
      " [[ 0.13243848 -0.13739452  0.15832603]\n",
      " [-0.02948982  0.24663693  0.13745135]] \n",
      "bias: None\n",
      "H->H \n",
      "matrix:\n",
      " [[-0.08127111 -0.57166946]\n",
      " [ 0.16144264 -0.6260332 ]] \n",
      "bias: [0.09293365 0.04699278]\n",
      "H->Y \n",
      "matrix:\n",
      " [[-0.15549159  0.5781991 ]] \n",
      "bias: [0.04719007]\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "# let's use seed so that the weights are initialized in a deterministic way\n",
    "torch.manual_seed(2)\n",
    "# create our RNN with some short dimensions\n",
    "my_rnn = mySRN(3, 2, 1, torch.nn.ReLU(), torch.nn.ReLU(), 'cpu')\n",
    "\n",
    "# printing initilized weights and biases \n",
    "print(\"X->H\", \"\\nmatrix:\\n\", tr2np(my_rnn.x_to_h.weight), \"\\nbias:\", my_rnn.x_to_h.bias)\n",
    "print(\"H->H\", \"\\nmatrix:\\n\", tr2np(my_rnn.h_to_h.weight), \"\\nbias:\", tr2np(my_rnn.h_to_h.bias))\n",
    "print(\"H->Y\", \"\\nmatrix:\\n\", tr2np(my_rnn.h_to_y.weight), \"\\nbias:\", tr2np(my_rnn.h_to_y.bias))\n",
    "\n",
    "# running the RNN on a sample input of size 2 and an initial hidden vector \n",
    "output = my_rnn.forward([torch.FloatTensor([0,0,1]), torch.FloatTensor([1,0,0])], \n",
    "                         torch.FloatTensor([1,1]))\n",
    "\n",
    "assert output[0].isclose(FloatTensor([0.04719005525112152])) \n",
    "assert output[1].isclose(FloatTensor([0.022266805171966553]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher if you have any doubts</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we do not need to write our own functions for common RNN architectures. \n",
    "Torch already provides the [necessary abstractions](https://pytorch.org/docs/stable/nn.html#recurrent-layers).\n",
    "\n",
    "The [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN) wrapper implements highly optimized forward routines to compute the hidden representations of a full input sequence.\n",
    "\n",
    "Some pointers:\n",
    "* Unlike our naive implementation, RNN accepts a 3-dimensional tensor of shape (seq_len, batch_shape, input_dim) rather than a list of 2-dimensional tensors\n",
    "* If no initial hidden state is provided, it defaults to a zero tensor\n",
    "* The class produces just the RNN hidden states; it is up to us to define the `h_to_y` transformation on top of them\n",
    "* The non-linearity argument is a string; our only two choices are either `\"tanh\"` or `\"relu\"` (shorthands for `torch.nn.Tanh` and `torch.nn.ReLU` respectively)\n",
    "\n",
    "**Read the documentation (!) for further details.**\n",
    "\n",
    "A brief example is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 32, 48])\n"
     ]
    }
   ],
   "source": [
    "rnn = torch.nn.RNN(input_size=16, hidden_size=48, nonlinearity=\"tanh\")\n",
    "X = torch.rand(10, 32, 16)\n",
    "h, _ = rnn(X)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for a random input tensor of shape (seq_len, batch_size, input_dim), we get back an output tensor of shape (seq_len, batch_size, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mySRN, rnn, X, h, my_rnn, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (2 points): A faster version of the SRN\n",
    "Now let's wrap an `RNN` into a custom module `fastSRN` that implements it aside from the `h_to_y` transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b91f77fde16d7ec13b95e31766b25646",
     "grade": false,
     "grade_id": "task2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class fastSRN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim: int, \n",
    "        hidden_dim: int, \n",
    "        output_dim: int, \n",
    "        hidden_activation: str,\n",
    "        output_activation: Callable[[FloatTensor], FloatTensor],\n",
    "        device: str\n",
    "    ) -> None:\n",
    "        super(fastSRN, self).__init__()\n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.output_activation = output_activation\n",
    "        self.device = device\n",
    "        \n",
    "        self.rnn= torch.nn.RNN(input_size=input_dim, hidden_size=hidden_dim, nonlinearity=self.hidden_activation)\n",
    "        self.h_to_y = torch.nn.Linear(in_features=hidden_dim, out_features=output_dim, bias=True)\n",
    "        \n",
    "    def forward(self, X:FloatTensor, h: Optional[FloatTensor]=None) -> FloatTensor:\n",
    "        h, _ = self.rnn(X)\n",
    "        y= self.output_activation(self.h_to_y(h))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see our new implementation in action. \n",
    "\n",
    "Initialize a random input tensor $X$ that would correspond to 32 sequences,  each of length 10, with each item having 16 features, and a `fastSRN` fit to process it, producing 42-dimensional hidden states and 2-dimensional output vectors for each sequence item.\n",
    "\n",
    "Run the SRN on the tensor and make sure the output shape is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_srn = fastSRN(\n",
    "    input_dim=16, hidden_dim=42, output_dim=2, \n",
    "    hidden_activation=\"tanh\", output_activation=torch.nn.Softmax(dim=-1), device=\"cpu\"\n",
    ")\n",
    "X = torch.rand(10, 32, 16)\n",
    "y = fast_srn(X)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again you can verify correctness of your implementation here, and as before, check whether it really does the computations what equations are describing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8d3bcd4c480e2a7e0eccb1d6f5bb3e4d",
     "grade": true,
     "grade_id": "task2-assert",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X->H \n",
      "matrix:\n",
      " [[ 0.16220331 -0.16827321  0.19390899]\n",
      " [-0.03611749  0.30206734  0.16834283]] \n",
      "bias: [0.09293365 0.04699278]\n",
      "H->H \n",
      "matrix:\n",
      " [[-0.08127111 -0.57166946]\n",
      " [ 0.16144264 -0.6260332 ]] \n",
      "bias: [-0.15549159  0.5781991 ]\n",
      "H->Y \n",
      "matrix:\n",
      " [[ 0.04719007  0.2932219 ]\n",
      " [ 0.29924387 -0.41714463]\n",
      " [-0.27183622  0.6800373 ]] \n",
      "bias: [-0.6925951  -0.04802549 -0.05603802]\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "torch.manual_seed(2)\n",
    "# create our RNN with some short dimensions\n",
    "fast_srn = fastSRN(3, 2, 3, 'relu', output_activation=torch.nn.Softmax(dim=-1), device='cpu')\n",
    "\n",
    "# printing initilized weights and biases \n",
    "print(\"X->H\", \"\\nmatrix:\\n\", tr2np(fast_srn.rnn.weight_ih_l0), \"\\nbias:\",  tr2np(fast_srn.rnn.bias_ih_l0))\n",
    "print(\"H->H\", \"\\nmatrix:\\n\", tr2np(fast_srn.rnn.weight_hh_l0), \"\\nbias:\", tr2np(fast_srn.rnn.bias_hh_l0))\n",
    "print(\"H->Y\", \"\\nmatrix:\\n\", tr2np(fast_srn.h_to_y.weight), \"\\nbias:\", tr2np(fast_srn.h_to_y.bias))\n",
    "\n",
    "\n",
    "# running the RNN on a sample input of size 2 \n",
    "output = fast_srn.forward(torch.FloatTensor([[[0,0,1]], [[1,0,0]]]))\n",
    "\n",
    "assert output.isclose(FloatTensor([[[0.22, 0.24, 0.54]],\n",
    "                                   [[0.21, 0.37, 0.42]]]),\n",
    "                      atol=0.01).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fast_srn, X, y, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher if you have any doubts</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed a minor complication: in order to utilize batching, we need our input sequences to be of the same length.\n",
    "\n",
    "This, however, is very rarely the case in practice. A common trick against this problem is _padding_; that is, appending zero tensors to all input sequences shorter than the maximum in-batch length to make them all equally long.\n",
    "\n",
    "As usual, torch already does the hard work for us via [pad_sequence](https://pytorch.org/docs/stable/nn.html?highlight=pad%20_sequence#torch.nn.utils.rnn.pad_sequence). Given a list of $N$ 2-dimensional tensors, each of shape (seq\\_len$_n$, input_dim), it will construct a 3-d tensor of shape ($max_{n \\in N}${seq\\_len$_n$}, N, input_dim).\n",
    "\n",
    "An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.rand(1, 3)  # a sequence of 1, 3-dimensional item\n",
    "x2 = torch.rand(4, 3)  # a sequence of 4, 3-dimensional items\n",
    "x3 = torch.rand(2, 3)  # a sequence of 2, 3-dimensional items\n",
    "\n",
    "X = torch.nn.utils.rnn.pad_sequence([x1, x2, x3])  \n",
    "\n",
    "# Can you guess what the shape of X is?\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare the ontents for better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8547, 0.4525, 0.6317]])\n",
      "tensor([[0.4760, 0.2200, 0.2166],\n",
      "        [0.2571, 0.0458, 0.1755],\n",
      "        [0.6177, 0.8291, 0.5246],\n",
      "        [0.2708, 0.7197, 0.3081]])\n",
      "tensor([[0.3892, 0.2259, 0.3430],\n",
      "        [0.0367, 0.7133, 0.6944]])\n",
      "==================================================\n",
      "tensor([[[0.8547, 0.4525, 0.6317],\n",
      "         [0.4760, 0.2200, 0.2166],\n",
      "         [0.3892, 0.2259, 0.3430]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000],\n",
      "         [0.2571, 0.0458, 0.1755],\n",
      "         [0.0367, 0.7133, 0.6944]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000],\n",
      "         [0.6177, 0.8291, 0.5246],\n",
      "         [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000],\n",
      "         [0.2708, 0.7197, 0.3081],\n",
      "         [0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "for i in [x1, x2, x3]: print(i)\n",
    "print(f\"{'':=^50}\\n{X}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x1, x2, x3, X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Word Embeddings\n",
    "Moving on --- in the last assignment, we saw how to train our own word embeddings using a small toy corpus. Now, we will see how to easily employ high-quality pretrained word vectors and, later on, how to utilize them for further downstream tasks.\n",
    "\n",
    "We are going to use [spaCy](https://spacy.io/). SpaCy is a high-level NLP library that provides a ton of useful functionalities, but we will only focus on its pretrained embeddings for this assignment.\n",
    "\n",
    "Before proceeding, [install spacy](https://spacy.io/usage) using your python package manager (e.g. `pip install spacy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy ver=3.4.3\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "print(f\"spacy ver={spacy.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy comes with a lot of different-size models for different languages. \n",
    "\n",
    "We will need to download the small english model for the exercises to follow. You can either do it in a new terminal window (optimal if you are running this assignment through a virtual environment) or by simply running the magic command below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having downloaded the model, we can load it as follows (you may need to restart your notebook after the download is complete):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the loaded model to process a sentence and obtain its word vectors, a List of 300-dimensional numpy arrays. [More info](https://spacy.io/models/en#en_core_web_lg) about vectors coming with `en_core_web_lg`.  \n",
    "We can also check similarities between the vectors, e.g., `words` is more similar to `sentence` than to `this`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 7 vectors, each of shape (300,) and of type <class 'numpy.ndarray'>\n",
      "'words' is 0.51 similar to 'sentence' and 0.36 similar to 'this'\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"this is a sentence of 7 words\")  # the processed sentence\n",
    "vectors = list(map(lambda x: x.vector, doc))  # its vectors\n",
    "# vectors = [ t.vector for t in doc ] $ or the same with list comprehension\n",
    "\n",
    "print(f\"We have {len(vectors)} vectors\", end=\", \")\n",
    "print(f\"each of shape {vectors[0].shape} and of type {type(vectors[0])}\")\n",
    "\n",
    "print(f\"'{doc[6]}' is {doc[6].similarity(doc[3]):.2f} similar to '{doc[3]}' and {doc[6].similarity(doc[0]):.2f} similar to '{doc[0]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then finally convert them into torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 300])\n"
     ]
    }
   ],
   "source": [
    "torch_vectors = torch.tensor(np.array(vectors))\n",
    "# torch_vectors = torch.tensor(vectors) # this is also fine but might get an efficiency warning from torch\n",
    "print(torch_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, in the case of multiple sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 300])\n"
     ]
    }
   ],
   "source": [
    "# Example sentences.\n",
    "sentences = [\"This is a sentence\", \"This is another sentence.\"]\n",
    "\n",
    "# Parallel processing with spacy.\n",
    "docs = list(map(nlp, sentences))\n",
    "\n",
    "# Convert each processed sentence into a list of vectors.\n",
    "vectors = map(lambda doc: [word.vector for word in doc], docs)\n",
    "\n",
    "# Convert each list of vectors into a 2-d torch tensor.\n",
    "tensors = list(map(lambda sentence_vectors: torch.tensor(np.array(sentence_vectors)), vectors))\n",
    "print(tensors[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging\n",
    "Given our pretrained embeddings, we may represent sentences as _sequences of vectors_, which is exactly the format expected by an RNN.\n",
    "We will now try to train an SRN to iterate over a sentence and assign part of speech tags to each of its words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (1 point): Examining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load and inspect our data files.\n",
    "\n",
    "The pickle file contains three items:\n",
    "1. `sentences`: a List of strings (sentences)\n",
    "2. `postags`: a List of Lists of strings (POS tags)\n",
    "3. `pos_to_int`: a Dictionary from strings to ints (mapping each POS tag to a unique identifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since many students had an issue with uploading files to colab, here is a convenient solution\n",
    "# if you use colab, download files on fly with the below two lines, no need to mount google drive or manually upload the files.\n",
    "#!wget https://naturallogic.pro/_files_/download/MLHVL/pos-rnn-data.zip\n",
    "#!unzip pos-rnn-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aca9d160d6729a074ea0a8712be8991f",
     "grade": false,
     "grade_id": "cell-d80555c635ad6c6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"TRAIN.p\", \"rb\") as f:\n",
    "    sentences, postags, pos_to_int = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sanity check that we have same number of sentences as pos tag annotations and for each sentence and annotation pairs, the number of tokens and tags are the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ddb88f1a046b994e110908db99970106",
     "grade": false,
     "grade_id": "cell-800a3348924a4bb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert all(list(map(lambda s, p: len(s.split()) == len(p), sentences, postags)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us take a moment to understand the data a bit more. \n",
    "Run the cell below with different values of `i` to get an idea of how the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e6171652ef86daca7959b30c71ade63c",
     "grade": false,
     "grade_id": "cell-b2be9a1c6f8a9323",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The/DT luxury/NN auto/NN maker/NN last/JJ year/NN sold/VBD 1,214/CD cars/NNS in/IN the/DT U.S./NNP "
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "for tok, tag in zip(sentences[i].split(), postags[i]):\n",
    "    print(f\"{tok}/{tag}\", end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The POS tags in this dataset are in the style of the Penn Treebank. Find the top 20 most common tags and plot a histogram of their frequencies, i.e., <ins>top 20 most frequent POS tags sitting on the x axis and y axis marking their raw counts</ins>. If you are curious, also find out what these tags mean linguisically! https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html  \n",
    "<font color=\"blue\">_Hint_: the 7th and 8th most frequent tags are punctuation marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "94b579ceb7b8f4fa03c5db730e2ec3ee",
     "grade": true,
     "grade_id": "task3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your plotting here\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "tag_count = defaultdict(int)\n",
    "for i in range(len(sentences)):\n",
    "    for tok, tag in zip(sentences[i].split(), postags[i]):\n",
    "        tag_count[tag]+=1\n",
    "value_key_pairs = [(value, key) for (key,value) in tag_count.items()]\n",
    "sorted_value_key_pairs = sorted(value_key_pairs, reverse=True)\n",
    "x=[]\n",
    "y=[]\n",
    "for no,tag in sorted_value_key_pairs[:20]:\n",
    "    x.append(tag)\n",
    "    y.append(no)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(x,y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher if you have any doubts</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (1 point): Tensorizing sentences\n",
    "Next, we need to convert our data to numeric form. Convert sentences to their tensor format, as done earlier (this may take a while). \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Important!</b>\n",
    "Since the sentences are pre-tokenized with whitespace (e.g., <code>One , two , and three .</code> instead of <code>One, two, and three.</code>), we need to change the processing call to ensure the output vectors are aligned with our tokenization (otherwise SpaCy will tokenize it in its own way and might break the correspondence between tokens and POS tags).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1147a53901d968ab340533fd7d54c197",
     "grade": false,
     "grade_id": "task4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = list(map(\n",
    "    lambda sentence: spacy.tokens.doc.Doc(nlp.vocab, words=sentence.split()), \n",
    "    sentences\n",
    "))\n",
    "doc_vectors=[]\n",
    "doc_tensors=[]\n",
    "for doc in docs:\n",
    "    vector=list(map(lambda x: x.vector, doc))\n",
    "    doc_vectors.append(vector)\n",
    "    doc_tensors.append(torch.tensor(np.array(vector)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8f6addb5bf5f7061f0438dcca228e092",
     "grade": true,
     "grade_id": "task4-assert",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert type(doc_tensors) == list\n",
    "assert doc_tensors[0].shape == torch.Size([45, 300])\n",
    "assert doc_tensors[1].shape == torch.Size([5, 300])\n",
    "assert doc_tensors[2].shape == torch.Size([12, 300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we will use `pos_to_int` to convert the POS sequences into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "58324fc4d2608755db6493d2e76523cf",
     "grade": false,
     "grade_id": "cell-e3f3ab6cbf388bc5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "torch.Size([5])\n",
      "tensor([12, 12, 26, 12, 14])\n"
     ]
    }
   ],
   "source": [
    "pos_numeric = list(map(lambda pos_sequence: [pos_to_int[pos] for pos in pos_sequence], postags))\n",
    "pos_tensors =  list(map(lambda pos_num_sequence: torch.tensor(pos_num_sequence), pos_numeric))\n",
    "\n",
    "print(type(pos_tensors))\n",
    "print(pos_tensors[1].shape)\n",
    "print(pos_tensors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del doc_vectors, docs, pos_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the tutorial, we saw how to split our dataset into a training and a validation set. \n",
    "\n",
    "Do the same here, splitting the sentences, postags and their corresponding tensors into a training and a validation set.  \n",
    "For the sake of determinism of the training, while splitting data, set shuffling `random_state` to 42 and select 0.2 of the data for validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d62c1b032c0b07c9a8bfefb7eebacc50",
     "grade": false,
     "grade_id": "task4-split",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "sentences_train, sentences_val, postags_train, postags_val, X_train, X_val, Y_train, Y_val \\\n",
    "    = train_test_split(sentences,postags,doc_tensors,pos_tensors,test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7339b0a5c42584cabc668b439cfd3134",
     "grade": true,
     "grade_id": "task4-split-assert",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TESTING for the sake of deteminism, make sure we have a correct version of the data split \n",
    "assert len(X_train) == len(Y_train) == len(sentences_train)\n",
    "assert len(X_val) == len(Y_val) == len(sentences_val)\n",
    "assert len(X_train) == 24157\n",
    "assert len(X_val) == 6040\n",
    "# 3rd sentence in training set has 36 tokens\n",
    "assert len(X_train[2]) == 36\n",
    "# checking pos tag indices of the sannotation of teh 3rd sentence in validation set  \n",
    "assert torch.all(Y_val[2] == LongTensor([12, 23, 25, 23,  1, 25, 36,  5,  1,  1, 22,  5,  1,  1, 14]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher if you have any doubts</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (1 point): Datasets and Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, following along the tutorial, we will wrap our tensors into a `Dataset` ([link](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)) and a `DataLoader` ([link](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)).\n",
    "\n",
    "Since our data are not Tensors but rather Lists of Tensors of uneven lengths, we need to write our own Dataset wrapper.\n",
    "The wrapper only needs to implement two functions; `__len__`, which expects no arguments and returns the number of samples in the dataset, and `__getitem__`, which accepts an index `idx` and returns the input-output pair `X[idx]`, `Y[idx]`.\n",
    "\n",
    "Similarly, the Dataloader needs to process the list of input-output pairs produced by the Dataset using `pad_sequence`, as seen earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the code for `UnevenLengthDataset` class, implementing its two core functions.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "If you have no experience creating container-like classes from scratch in Python, refer to the documentation for the <a href=\"https://docs.python.org/3/reference/datamodel.html#special-method-names\">special class methods</a> and for <a href=\"https://docs.python.org/3/reference/datamodel.html#emulating-container-types\">emulating container types</a>. Talk to your teacher if needed.</div>\n",
    "\n",
    "Then, complete the function `pad_batch` which takes a list of \n",
    "(x$_i$, y$_i$) pairs and produces the pair of their paddings: (X, Y).\n",
    "\n",
    "Given the two, the `DataLoader` object can iterate over the Dataset yielding uniform batches ready to be consumed by an RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ed8a6e1cbd5a3df849aaec3303c863e9",
     "grade": false,
     "grade_id": "task5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class UnevenLengthDataset(Dataset):\n",
    "    def __init__(self, X: List[FloatTensor], Y: List[LongTensor]) -> None:\n",
    "        self.x=X\n",
    "        self.y=Y\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.x)\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple[FloatTensor, LongTensor]:\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "    \n",
    "def pad_batch(batch: List[Tuple[FloatTensor, LongTensor]]) -> Tuple[FloatTensor, LongTensor]:\n",
    "    x=[pair[0] for pair in batch]\n",
    "    y=[pair[1] for pair in batch]\n",
    "    x_padding = torch.nn.utils.rnn.pad_sequence(x) \n",
    "    y_padding = torch.nn.utils.rnn.pad_sequence(y) \n",
    "    return (x_padding,y_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4eae9d11c5a697faddf346b86a7bd7b1",
     "grade": false,
     "grade_id": "cell-b068529415037344",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = UnevenLengthDataset(X_train, Y_train)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    collate_fn=pad_batch,\n",
    "    shuffle=True, #data will be reshuffled at every epoch\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_dataset = UnevenLengthDataset(X_val, Y_val)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    collate_fn=pad_batch,\n",
    "    shuffle=False,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does a batch look like, shape-wise? Get the first element of `train_dataloader` to find out.  \n",
    "Try to understand what each number in the shape means.  \n",
    "<font color=\"blue\">_Hint_: 42 is the length of a sequecne in the batch, but why 42? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42, 32, 300])\n",
      "torch.Size([42, 32])\n"
     ]
    }
   ],
   "source": [
    "# without the seed, every time you run this cell, it will give a random batch\n",
    "torch.manual_seed(2)\n",
    "for batch_x, batch_y in train_dataloader:\n",
    "    print(batch_x.shape)\n",
    "    print(batch_y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher if you have any doubts</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good. On to the network.\n",
    "\n",
    "### Task 6 (2 points): Utility Functions\n",
    "Remember how we defined our training and validation functions in the tutorial?\n",
    "\n",
    "You will need to do the same here.\n",
    "Note that while you can use the code from the tutorial for guidance, just copying it won't do the trick; unlike a feedforward net, a recurrent network produces a 3rd order output tensor of shape (max_seq_len, batch_size, num_output_classes).\n",
    "\n",
    "Similarly, our target Y is a 2nd order tensor of shape (max_seq_len, batch_size).\n",
    "\n",
    "You will need to properly treat the extra dimension of both the output and the target, since loss functions expect an order 2 output tensor and an order 1 target tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions `accuracy` and `measure_accurace`, which will be needed during evaluation, are already provided to you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "613aa250b6bd49e482ce344197d8cfec",
     "grade": false,
     "grade_id": "cell-65714e6365343efd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions: LongTensor, truth: LongTensor, ignore_idx: int) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Compute the total count of non-ignored values and total count of correctly predicted values.\n",
    "        \n",
    "    :param predictions: the network's predictions\n",
    "    :param truth: the true output labels\n",
    "    :param ignore_idx: the output padding value, to be ignored in accuracy calculation\n",
    "    :return: the total count of non-ignored values, the total count of correctly predicted values\n",
    "    \"\"\"\n",
    "    correct_words = torch.ones(predictions.size())\n",
    "    # Zero out the incorrectly predicted values.\n",
    "    correct_words[predictions != truth] = 0\n",
    "    # Mark with 1 the values that need to be ignored.\n",
    "    correct_words[truth == ignore_idx] = 1\n",
    "    # Calculate the total count of correctly predicted values, incl. the ignored ones.\n",
    "    num_correct_words = correct_words.sum().item()\n",
    "    # Calculate the number of the values to be ignored.\n",
    "    num_masked_words = len(truth[truth == ignore_idx])\n",
    "    #\n",
    "    count_non_ignored = predictions.shape[0] * predictions.shape[1] - num_masked_words\n",
    "    count_correct = num_correct_words - num_masked_words\n",
    "    return count_non_ignored, count_correct\n",
    "\n",
    "\n",
    "def measure_accuracy(network: torch.nn.Module, dataloader: DataLoader, device: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute the network's accuracy across all batches.\n",
    "    \n",
    "    :param network: the trained network\n",
    "    :param dataloader: the dataloader for the validation data\n",
    "    :param device: the device to store the data on (\"cpu\" or \"cuda\")\n",
    "    :return: the network's accuracy\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Iterate over the batches.\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        # Get the network predictions.\n",
    "        pred = network(x_batch.to(device))\n",
    "        # Compute the values to measure accuracy for the current batch.\n",
    "        # note that pos tags are mapped to numbers 1..48 and we can safely use 0 for making dummy padding slots\n",
    "        local_total, local_correct = accuracy(pred.argmax(dim=-1), y_batch.to(device), ignore_idx=0)\n",
    "        # Update the total counts.\n",
    "        correct += local_correct\n",
    "        total += local_total\n",
    "    # Compute the final accuracy across all batches.\n",
    "    acc = correct/total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3.0)\n",
      "(8, 6.0)\n"
     ]
    }
   ],
   "source": [
    "# If you want to understadn how accuracy works, you can verify these toy input/output pairs \n",
    "print(accuracy(LongTensor([[1,2,0,0], [3,4,5,0]]), LongTensor([[1,3,0,0], [1,4,5,0]]), ignore_idx=0))\n",
    "print(accuracy(LongTensor([[1,2,0,0], [3,4,5,0]]), LongTensor([[1,3,0,0], [1,4,5,0]]), ignore_idx=9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the functions `train_batch`, `train_epoch`, `eval_batch` and `eval_epoch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b2cbf9657554856b6f929b078c809013",
     "grade": true,
     "grade_id": "task6",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_batch(\n",
    "    network: torch.nn.Module,\n",
    "    X_batch: FloatTensor,\n",
    "    Y_batch: LongTensor,\n",
    "    loss_fn: Callable[[FloatTensor, FloatTensor], FloatTensor],  \n",
    "    optimizer: torch.optim.Optimizer\n",
    ") -> float: #batch-specific loss\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def train_epoch(\n",
    "    network: torch.nn.Module, \n",
    "    dataloader: DataLoader,\n",
    "    loss_fn: Callable[[FloatTensor, FloatTensor], FloatTensor],\n",
    "    optimizer: torch.optim.Optimizer, \n",
    "    device: str\n",
    ") -> float: #epoch's loss\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def eval_batch(\n",
    "    network: torch.nn.Module,\n",
    "    X_batch: FloatTensor,\n",
    "    Y_batch: LongTensor,\n",
    "    loss_fn: Callable[[FloatTensor, LongTensor], FloatTensor]\n",
    ") -> float: #batch-specific loss\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def eval_epoch(\n",
    "    network: torch.nn.Module, \n",
    "    dataloader: DataLoader,\n",
    "    loss_fn: Callable[[FloatTensor, LongTensor], FloatTensor],\n",
    "    device: str\n",
    ") -> float: #epoch's loss\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher if you have any doubts</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 (2 points): SRN POS tagging\n",
    "Define a simple recurrent network, with input size compatible with the vector dimensionality, output size compatible with the number of output classes (the number of different POS tags + 1 due to usig 0 as padding in pos tag annotations) and a hidden size of your own choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>Use `\"tanh\"` as your hidden layer activation</ins>, and choose <ins>an appropriate combination of output activation and loss function</ins> (consider the task at hand and refer to the documentation or the tutorial if in doubt).\n",
    "\n",
    "Then instantiate an optimizer over your network and train the network for a number of epochs (<ins>at least 3</ins> so that it make sense to plot the results), measuring and printing all metrics in the process (train and validation loss and accuracy).\n",
    "\n",
    "<font color=\"blue\">_Hint_: Use `measure_accuracy` (defined earlier) to obtain accuracy. For the debugging you can try shorter hidden vectors and a single epoch. \n",
    "\n",
    "Plot the loss and accuracy curves over the training process, i.e., x-axis for epoch number and y-axis for loss/accuracy values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "39179199d20e4fb65bd26cc98259453f",
     "grade": true,
     "grade_id": "task7-rnn",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for deterministic initialization of weights\n",
    "torch.manual_seed(0)\n",
    "\n",
    "srn = NotImplemented\n",
    "opt = NotImplemented\n",
    "loss_fn = NotImplemented\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0caa7c12be3217d8f19169ec868867a6",
     "grade": true,
     "grade_id": "task7-train",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your training script here\n",
    "# note that if you don't initialize srn from scratch, running this cell 2nd time will mean \n",
    "# training the already trained parameters for further epochs\n",
    "# Seed makes sure that shuffles in training set is consistent for each run of this cell\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "466ae6c6a315012d464cde9ae6aaad10",
     "grade": true,
     "grade_id": "loss_plot",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your loss plotting here: x-axis for epochs and y-axis for train and validation losses\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8966548626433a8890d44b2f1ba01693",
     "grade": true,
     "grade_id": "acc_plot",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your accuracy plotting here: x-axis for epochs and y-axis for train and validation accuracies\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy on this task should be well over 90%. If you are getting an accuracy much below this, check your code, play with your hyperparameters and try to improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Show the completed code to your teacher if you have any doubts</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 (2 points): Error analysis\n",
    "<ins>Find 2-4 sentences from the validation set</ins> where the network predicted wrong POS tags. For at least 2 different types of the mistakes, make suggestions as to why they were made. Refer to the [POS tags](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) for the POS tag descriptions and the [POS tag annotation guidelines](https://www.cis.upenn.edu/~bies/manuals/tagguide.pdf) which defines when a particular POS tag should and should not be used. \n",
    "\n",
    "Write a code that automatically picks such 2-4 sentecnes. Print the sentecne tokens with the corresponding correct and system predicted POS tags in an aligned way that makes readining easy. Make it clear which tag is system predicted and which correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2fad5011834d2c48499b3baf5bf5a678",
     "grade": true,
     "grade_id": "task8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2e175d359251dc02adda71060a67daaf",
     "grade": true,
     "grade_id": "task8-answer",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9 (2 points): Extended error analysis\n",
    "\n",
    "What are the most commonly confused pairs of POS tags (select the top 3-5 pairs)? Provide illustrations from the data and make suggestions as to why these tag pairs are frequently confused.  \n",
    "\n",
    "Write the code that finds the most confused POS tags pairs. Note that the pairs are not symmetric: one is correct and another system predicted. Make it clear which part of the pair is which. You can use a couple of code cells for printing examples.  \n",
    "\n",
    "<font color=\"blue\">_Hint_: In top 5 confused pairs, there shoudl be `NN` occuring more than once.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4177e8d6f2a0054d4646b5082b676c6c",
     "grade": true,
     "grade_id": "task9-1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2a25791d6b8bbe1590778c442ac81d3d",
     "grade": true,
     "grade_id": "task9-2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6848a3488a909f819c90809c30315eca",
     "grade": true,
     "grade_id": "task9-answer",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations!\n",
    " You are done with the required part! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional\n",
    "\n",
    "RNNs have limited expressive capacity that can be surpassed by more complicated variants such as [Gated Recurrent Units](https://en.wikipedia.org/wiki/Gated_recurrent_unit) and [Long Short-Term Memory Units](https://en.wikipedia.org/wiki/Long_short-term_memory); replacing your RNN with those could easily improve the performance.\n",
    "\n",
    "If you found the previous part easy and are already done, you can use other neural architectures to do the same task on the same dataset and compare their performance.  (There will be no support provided for this, or points, but you are welcome to explore this for your own understanding :))\n",
    "\n",
    "Whatever your design choices are, keep the torch documentation close at all times! Do not reinvent the wheel, use existing abstractions whenever possible (but make sure you use them the right way!). Take measures against overfitting: regularize with dropout and/or weight decay and keep track of the validation set performance to stop training early if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
